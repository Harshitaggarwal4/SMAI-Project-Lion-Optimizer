{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Table of Contents\n","\n","* [Overview](#0)\n","* [Importing Libraries](#1)\n","* [Load Dataset](#2)\n","* [Data Visualization](#3)\n","* [Text Preprocessing](#4)\n","* [Build Model with Pytorch](#5)\n","* [Prediction](#7)"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T07:23:51.654360Z","iopub.status.busy":"2023-11-28T07:23:51.654012Z","iopub.status.idle":"2023-11-28T07:24:06.167087Z","shell.execute_reply":"2023-11-28T07:24:06.165940Z","shell.execute_reply.started":"2023-11-28T07:23:51.654314Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting nltk==3.8\n","  Downloading nltk-3.8-py3-none-any.whl (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk==3.8) (8.1.7)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk==3.8) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk==3.8) (2023.8.8)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk==3.8) (4.66.1)\n","Installing collected packages: nltk\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.2.4\n","    Uninstalling nltk-3.2.4:\n","      Successfully uninstalled nltk-3.2.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nltk-3.8\n"]}],"source":["# nltk is one of the most useful libraries when it comes to nlp\n","!pip install nltk==3.8"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"0\"></a>\n","# Overview\n","\n","In this notebook, we are going to do semantic analysis on hotel reviews from Tripadvisor. We will 2 different approaches:\n","1. With machine learning models using sklearn\n","2. With deep neural network using tensorflow\n","\n","There are also some text preprocessing before we train our model to make sure that our data is clean. At the end of this notebook, we will try to predict the sentiment of our own review\n","\n","**So, let's dive into the code!**"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"1\"></a>\n","# Importing Libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-28T07:24:06.169705Z","iopub.status.busy":"2023-11-28T07:24:06.169311Z","iopub.status.idle":"2023-11-28T07:24:20.184930Z","shell.execute_reply":"2023-11-28T07:24:20.183979Z","shell.execute_reply.started":"2023-11-28T07:24:06.169670Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]},{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import string\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from wordcloud import WordCloud\n","\n","# Preprocessing and evaluation\n","from nltk.corpus import stopwords\n","from nltk.stem.snowball import SnowballStemmer\n","from nltk.stem.wordnet import WordNetLemmatizer\n","from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Models\n","import torch\n","from tqdm import tqdm\n","torch.cuda.is_available()"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"1\"></a>\n","# Load Dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T07:24:20.186464Z","iopub.status.busy":"2023-11-28T07:24:20.185944Z","iopub.status.idle":"2023-11-28T07:24:20.576308Z","shell.execute_reply":"2023-11-28T07:24:20.575480Z","shell.execute_reply.started":"2023-11-28T07:24:20.186438Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Review</th>\n","      <th>Rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>nice hotel expensive parking got good deal sta...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ok nothing special charge diamond member hilto...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>nice rooms not 4* experience hotel monaco seat...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>unique, great stay, wonderful time hotel monac...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>great stay great stay, went seahawk game aweso...</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              Review  Rating\n","0  nice hotel expensive parking got good deal sta...       4\n","1  ok nothing special charge diamond member hilto...       2\n","2  nice rooms not 4* experience hotel monaco seat...       3\n","3  unique, great stay, wonderful time hotel monac...       5\n","4  great stay great stay, went seahawk game aweso...       5"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('../input/trip-advisor-hotel-reviews/tripadvisor_hotel_reviews.csv')\n","df.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T07:24:20.578734Z","iopub.status.busy":"2023-11-28T07:24:20.578442Z","iopub.status.idle":"2023-11-28T07:24:20.603139Z","shell.execute_reply":"2023-11-28T07:24:20.602245Z","shell.execute_reply.started":"2023-11-28T07:24:20.578709Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 20491 entries, 0 to 20490\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   Review  20491 non-null  object\n"," 1   Rating  20491 non-null  int64 \n","dtypes: int64(1), object(1)\n","memory usage: 320.3+ KB\n"]}],"source":["df.info()"]},{"cell_type":"markdown","metadata":{},"source":["As you can see from above details, there is **no null values** in this dataset"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"4\"></a>\n","# Text Preprocessing"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T07:24:20.652059Z","iopub.status.busy":"2023-11-28T07:24:20.651786Z","iopub.status.idle":"2023-11-28T07:24:20.657448Z","shell.execute_reply":"2023-11-28T07:24:20.656593Z","shell.execute_reply.started":"2023-11-28T07:24:20.652038Z"},"trusted":true},"outputs":[],"source":["# Let's change the rating to be more general and easier to understand\n","def rating(score):\n","    if score > 3:\n","        return 2 # Good\n","    elif score == 3:\n","        return 1 # Neutral\n","    else:\n","        return 0 # Bad"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T07:24:20.658912Z","iopub.status.busy":"2023-11-28T07:24:20.658588Z","iopub.status.idle":"2023-11-28T07:24:20.681671Z","shell.execute_reply":"2023-11-28T07:24:20.680825Z","shell.execute_reply.started":"2023-11-28T07:24:20.658889Z"},"trusted":true},"outputs":[],"source":["df['Rating'] = df['Rating'].apply(rating)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T07:24:20.683254Z","iopub.status.busy":"2023-11-28T07:24:20.682929Z","iopub.status.idle":"2023-11-28T07:24:20.691494Z","shell.execute_reply":"2023-11-28T07:24:20.690593Z","shell.execute_reply.started":"2023-11-28T07:24:20.683225Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Review</th>\n","      <th>Rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>nice hotel expensive parking got good deal sta...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ok nothing special charge diamond member hilto...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>nice rooms not 4* experience hotel monaco seat...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>unique, great stay, wonderful time hotel monac...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>great stay great stay, went seahawk game aweso...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              Review  Rating\n","0  nice hotel expensive parking got good deal sta...       2\n","1  ok nothing special charge diamond member hilto...       0\n","2  nice rooms not 4* experience hotel monaco seat...       1\n","3  unique, great stay, wonderful time hotel monac...       2\n","4  great stay great stay, went seahawk game aweso...       2"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Lemmatization"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T07:24:20.701494Z","iopub.status.busy":"2023-11-28T07:24:20.701162Z","iopub.status.idle":"2023-11-28T07:24:20.712122Z","shell.execute_reply":"2023-11-28T07:24:20.711281Z","shell.execute_reply.started":"2023-11-28T07:24:20.701470Z"},"trusted":true},"outputs":[],"source":["def cleaning(text):\n","    #remove punctuations and uppercase\n","    clean_text = text.translate(str.maketrans('','',string.punctuation)).lower()\n","    \n","    #remove stopwords\n","    clean_text = [word for word in clean_text.split() if word not in stopwords.words('english')]\n","    \n","    #lemmatize the word\n","    sentence = []\n","    for word in clean_text:\n","        lemmatizer = WordNetLemmatizer()\n","        sentence.append(lemmatizer.lemmatize(word, 'v'))\n","\n","    return ' '.join(sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T07:24:20.713241Z","iopub.status.busy":"2023-11-28T07:24:20.712993Z"},"trusted":true},"outputs":[],"source":["df['Review'] = df['Review'].apply(cleaning)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# After cleaning, let's see the most common used word\n","plt.figure(figsize=(20,20))\n","wc = WordCloud(max_words=1000, min_font_size=10, \n","                height=800,width=1600,background_color=\"white\").generate(' '.join(df['Review']))\n","\n","plt.imshow(wc)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.to_csv(\"/kaggle/working/processed_data.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = pd.read_csv(\"/kaggle/working/processed_data.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Set a random seed for reproducibility\n","random_seed = 42\n","\n","# First, split into training and temporary set (combining validation and test)\n","X_train_temp, X_test, y_train_temp, y_test = train_test_split(\n","    df['Review'], df['Rating'], test_size=0.2, random_state=random_seed\n",")\n","\n","# Now split the temporary set into validation and test sets\n","X_train, X_valid, y_train, y_valid = train_test_split(\n","    X_train_temp, y_train_temp, test_size=0.25, random_state=random_seed  # 0.25 x 0.8 = 0.2\n",")"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"5\"></a>\n","# Building Model with Pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# build vocabulary, convert text => number\n","tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n","\n","tokenizer.fit_on_texts(X_train)\n","# print(tokenizer.word_index)\n","total_word = len(tokenizer.word_index)\n","print('Total distinct words: {}'.format(total_word))\n","\n","X_train = tokenizer.texts_to_sequences(X_train)\n","X_train = pad_sequences(X_train, maxlen=80)\n","\n","X_valid = tokenizer.texts_to_sequences(X_valid)\n","X_valid = pad_sequences(X_valid, maxlen=80)\n","\n","X_test = tokenizer.texts_to_sequences(X_test)\n","X_test = pad_sequences(X_test, maxlen=80)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y_train = y_train.to_numpy()\n","y_valid = y_valid.to_numpy()\n","y_test = y_test.to_numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y_train.shape"]},{"cell_type":"markdown","metadata":{},"source":["# BiLSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class SentimentAnalysis(torch.nn.Module):\n","\n","    def __init__(self, total_word, embed_size, hidden_size, num_class, padding_index=0):\n","        super().__init__()\n","        self.total_word = total_word\n","        self.embed_size = embed_size\n","        self.hidden_size = hidden_size\n","        self.num_class = num_class\n","        \n","        self.embed = torch.nn.Embedding(num_embeddings=total_word, \n","                                        embedding_dim=embed_size, \n","                                        padding_idx=padding_index)\n","        self.lstm = torch.nn.LSTM(input_size=self.embed_size, \n","                                  hidden_size=self.hidden_size, \n","                                  num_layers=1,\n","                                  bidirectional=True,\n","                                  batch_first=True)\n","        self.classifier = torch.nn.Sequential(\n","            # TODO: add more Linear layer, Activation layer\n","            torch.nn.Linear(in_features=2*self.hidden_size, out_features=num_class)\n","        )\n","        \n","    def forward(self, X):\n","        out = self.embed(X)\n","        out, _ = self.lstm(out)\n","        out = self.classifier(out[:, -1, :])\n","        return out"]},{"cell_type":"markdown","metadata":{},"source":["# Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class lion_optimizer(torch.optim.Optimizer): \n","\n","    def __init__(self, params, learning_rate = 1e-3, beta1 = 0.9, beta2 = 0.99, lambdaa = 0.01):\n","        super(lion_optimizer, self).__init__(params, defaults={'lr': learning_rate})\n","        self.state = dict()\n","        self.beta1 = beta1\n","        self.beta2 = beta2\n","        self.lambdaa = lambdaa\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                self.state[p] = dict(momentum = torch.zeros_like(p.data))\n","\n","    def step(self): \n","        for group in self.param_groups:\n","            for p in group['params']:\n","                if p not in self.state: \n","                    self.state[p] = dict(momentum = torch.zeros_like(p.data))\n","                m = self.beta1 * self.state[p]['momentum'] + (1 - self.beta1) * p.grad.data\n","                p.data -= group['lr'] * (torch.sign(m) + self.lambdaa * p.data)\n","                m = self.beta2 * self.state[p]['momentum'] + (1 - self.beta2) * p.grad.data\n","                self.state[p]['momentum'] = m"]},{"cell_type":"markdown","metadata":{},"source":["# Training Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["NUM_VOCAB = total_word\n","EMBED_SIZE = 128\n","HIDDEN_SIZE = 164\n","NUM_CLASS = 3\n","BATCH_SIZE = 32\n","EPOCHS = 20\n","LAMBDA = 0.01\n","\n","lion_learningRate_ablation_train_accuracy = {}\n","lion_learningRate_ablation_valid_accuracy = {}\n","\n","num_train = X_train.shape[0]\n","num_valid = X_valid.shape[0]\n","inds = np.arange(num_train)\n","inds_valid = np.arange(num_valid)\n","\n","# Define your optimizer\n","loss_func = torch.nn.CrossEntropyLoss()\n","\n","# Helper function to calculate accuracy\n","def calculate_accuracy(y_pred, y_true):\n","    _, predicted = torch.max(y_pred.data, 1)\n","    total = y_true.size(0)\n","    correct = (predicted == y_true).sum().item()\n","    return correct / total\n","\n","lambdaas = np.concatenate((np.arange(0.001, 0.01, 0.001), np.arange(0.01, 0.1, 0.01), np.arange(0.1, 1.1, 0.1)))\n","\n","for lambdaa in lambdaas:\n","    lion_learningRate_ablation_train_accuracy[lr] = []\n","    lion_learningRate_ablation_valid_accuracy[lr] = []\n","    model = SentimentAnalysis(total_word=NUM_VOCAB, embed_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE, num_class=NUM_CLASS)\n","    model = model.to(\"cuda\")\n","    optimizer = lion_optimizer(model.parameters(), learning_rate=0.0001, lambdaa=lambdaa)\n","    BATCH_SIZE = 128\n","    EPOCH = 20\n","    print(\"\")\n","    print(lr)\n","    \n","    for e in range(EPOCH):\n","        model.train()\n","        total = 0\n","        correct = 0\n","        pbar = tqdm(range(0, X_train.shape[0], BATCH_SIZE), desc=\"Epoch {}\".format(e+1))\n","        for i in pbar:\n","            x = torch.Tensor(X_train[inds[i:i+BATCH_SIZE]])\n","            x = x.type(dtype=torch.IntTensor).to(\"cuda\")\n","            y_hat = model(x)\n","            y = torch.Tensor(y_train[inds[i:i+BATCH_SIZE]])\n","            y = y.type(dtype=torch.LongTensor).to(\"cuda\")\n","            loss = loss_func(y_hat, y)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Calculate accuracy\n","            _, predicted = torch.max(y_hat.data, 1)\n","            total += y.size(0)\n","            correct += (predicted == y).sum().item()\n","\n","            # Update progress bar\n","            train_accuracy = 100 * correct / total\n","            pbar.set_description(\"Epoch: {} - Loss: {:.4f} - Acc: {:.2f}%\".format(e + 1, loss.item(), train_accuracy))\n","        \n","        lion_learningRate_ablation_train_accuracy[lr].append(100 * correct / total)\n","\n","        # Validation Accuracy Calculation\n","        model.eval()\n","        with torch.no_grad():\n","            pbar = tqdm(range(0, X_valid.shape[0], BATCH_SIZE), desc=\"Epoch {}\".format(e+1))\n","            correct  = 0\n","            total = 0\n","            for i in pbar:\n","                x = torch.Tensor(X_valid[inds_valid[i:i+BATCH_SIZE]])\n","                x = x.type(dtype=torch.IntTensor).to(\"cuda\")\n","                y_hat = model(x)\n","                y = torch.Tensor(y_valid[inds_valid[i:i+BATCH_SIZE]])\n","                y = y.type(dtype=torch.LongTensor).to(\"cuda\")\n","\n","                # Calculate accuracy\n","                _, predicted = torch.max(y_hat.data, 1)\n","                total += y.size(0)\n","                correct += (predicted == y).sum().item()\n","\n","            # Update progress bar\n","            valid_accuracy = 100 * correct / total\n","            \n","            lion_learningRate_ablation_valid_accuracy[lr].append(valid_accuracy)\n","            \n","            print(\"Validation Accuracy : \",valid_accuracy)\n","                \n","           "]},{"cell_type":"markdown","metadata":{},"source":["# Saving Results"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import json\n","\n","# Save the dictionary to a file\n","with open('lion_weightDecay_ablation_train_accuracy.json', 'w') as file:\n","    json.dump(lion_learningRate_ablation_train_accuracy, file)\n","\n","\n","# Save the dictionary to a file\n","with open('lion_weightDecay_ablation_valid_accuracy.json', 'w') as file:\n","    json.dump(lion_learningRate_ablation_valid_accuracy, file)\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":897156,"sourceId":1526618,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
